{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcA-oLUnIJsd",
        "outputId": "dd80f68a-3550-4d76-9f5c-cbb829b24156"
      },
      "outputs": [],
      "source": [
        "!pip install \"sb3_contrib>=2.0.0a1\" --upgrade\n",
        "!pip install \"stable_baselines3>=2.0.0a1\" --upgrade\n",
        "!pip install pvlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwQ-akxFkQjO"
      },
      "source": [
        "## Download the folder \"BEAR\" and upload it to your Drive in \"My Drive\", then run the cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mCG5hOMkEjO",
        "outputId": "f5bf10db-a578-4a74-d82f-ade75ce849bd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "\n",
        "os.chdir(\"gdrive/My Drive/BEAR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV1HWteUkaAi"
      },
      "outputs": [],
      "source": [
        "from Env.build_env2  import BuildingEnvReal\n",
        "from Data.MPC_Controller import MPCAgent\n",
        "from Utils.bldg_utils2 import ParameterGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GvZr6O-k2Gx"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHjAJwEpmG8f"
      },
      "source": [
        "We start by creating an environment with a OfficeSmall type building at Tucson, and setting the weather type as Hot Dry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvoEJqy4lkDD",
        "outputId": "6320e7e5-eded-4d35-dd10-4eaf616dff77"
      },
      "outputs": [],
      "source": [
        "Parameter=ParameterGenerator('OfficeSmall','Hot_Dry','Tucson',root='Data/')  #Description of ParameterGenerator in bldg_utils.py\n",
        "#Create environment\n",
        "env = BuildingEnvReal(Parameter)\n",
        "numofhours=24\n",
        "#Initialize\n",
        "env.reset()\n",
        "for i in range(numofhours):\n",
        "    a = env.action_space.sample()#Randomly select an action\n",
        "    obs, r, terminated, truncated, _ = env.step(a)#Return observation and reward\n",
        "RandomController_state=env.statelist #Collect the state list \n",
        "RandomController_action=env.actionlist #Collect the action list "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRMZ-w3CBE8s"
      },
      "source": [
        "The state space:$$s_k=[T_1[k],T_2[k], ...,T_{M}[k],Q_p[k],T_G[k],T_{E}[k],Q_{ghi}[k]]$$\n",
        "\n",
        "The action space:$$a_k=[Q^z_{1}[k],Q^z_{2}[k],...,Q^z_{M}[k]]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-NnwQXrAYn",
        "outputId": "bff3766d-977d-40f4-8f22-3dadaddb10ed"
      },
      "outputs": [],
      "source": [
        "obs_dim = env.observation_space.shape[0]\n",
        "print(\"Size of State Space ->  {}\".format(obs_dim))\n",
        "action_dim = env.action_space.shape[0]\n",
        "print(\"Size of Action Space ->  {}\".format(action_dim))\n",
        "upper_bound = env.action_space.high[0]\n",
        "lower_bound = env.action_space.low[0]\n",
        "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
        "print(\"Min Value of Action ->  {}\".format(lower_bound))\n",
        "print('Sample State :', RandomController_state[0])\n",
        "print('Sample Action :', RandomController_action[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnOEOimqCOO1"
      },
      "source": [
        "###No Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7dgNKAIm5rJ"
      },
      "source": [
        "We first test the environment with no actions. Let's loop for 24 hours and plot the temperature and energy comsumption of each zones :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "UAu-KAaUlm7P",
        "outputId": "5f4ffec8-b1af-4cba-fc67-0629f18552e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "numofhours=24\n",
        "env.reset()\n",
        "a=env.action_space.sample()\n",
        "for i in range(numofhours):\n",
        "    a = a*0\n",
        "    obs, r, terminated, truncated, _ = env.step(a)\n",
        "plt.plot(np.array(env.statelist)[:,:-3])\n",
        "plt.title('Our Model Temperature')\n",
        "\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Celsius')\n",
        "\n",
        "plt.legend(['South','East','North','West','Core','Plenum','Outside'],loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(np.sum(np.abs(np.array(env.actionlist)),1))\n",
        "\n",
        "plt.title('Our Model Power')\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Watts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoowP_l2npv4",
        "outputId": "8144ce16-9cdb-442e-efd6-9e40144af3df"
      },
      "outputs": [],
      "source": [
        "print('zone temerature at 1 a.m. :', np.array(env.statelist)[1,:-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjLijMJxCLCa"
      },
      "source": [
        "###MPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLyKJtplqDVt"
      },
      "source": [
        "Then we use a MPC controller and set each room at 22 degrees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "2U2EFaUFpgoW",
        "outputId": "4e833480-2ad6-46da-8674-80f2de2e3300"
      },
      "outputs": [],
      "source": [
        "agent = MPCAgent(env,\n",
        "                gamma=env.gamma,\n",
        "                safety_margin=0.96, planning_steps=10)\n",
        "env.reset()\n",
        "numofhours=24\n",
        "reward_total=0\n",
        "for i in range(numofhours):\n",
        "    a,s = agent.predict(env)\n",
        "    obs, r, terminated, truncated, _ = env.step(a)\n",
        "    reward_total+=r\n",
        "print('total reward is: ',reward_total)\n",
        "plt.plot(np.array(env.statelist)[:,:-3])\n",
        "plt.title('Our Model Temperature')\n",
        "\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Celsius')\n",
        "plt.legend(['South','East','North','West','Core','Plenum','Outside'],loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(np.sum(np.abs(np.array(env.actionlist)),1))\n",
        "plt.title('Our Model Power')\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Watts')\n",
        "plt.show()\n",
        "MPCstate=env.statelist\n",
        "MPCaction=env.actionlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcZWfBX4qnOt",
        "outputId": "7e3d9888-a0eb-4b21-ca92-bd2eda3481c7"
      },
      "outputs": [],
      "source": [
        "print('zone temerature:', np.array(env.statelist)[0,:-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXQdt-0kCDG-"
      },
      "source": [
        "### Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIRNRNPIxuIq"
      },
      "source": [
        "Finally, we use a PPO controller to demonstrate RL usage. We perform a quick train with default settings and save the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g81VmHLz0R40"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO ,DQN,DDPG\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.ppo import MlpPolicy\n",
        "# from stable_baselines.bench import Monitor\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EphrYEoZrVFy",
        "outputId": "610d1684-9a39-44e8-abd6-489d28c6bf39"
      },
      "outputs": [],
      "source": [
        "\n",
        "seed=25\n",
        "env.reset()\n",
        "set_random_seed(seed=seed)\n",
        "model = PPO(MlpPolicy, env, verbose=1)\n",
        "rewardlist=[]\n",
        "\n",
        "for i in range(300):  \n",
        "  model.learn(total_timesteps=1000)\n",
        "  rw=0\n",
        "  vec_env = model.get_env()\n",
        "  obs = vec_env.reset()\n",
        "  for i in range(24):\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = vec_env.step(action)\n",
        "    rw+=rewards\n",
        "  print(rw/24)\n",
        "  rewardlist.append(rw/24)\n",
        "print(\"################TRAINING is Done############\")\n",
        "model.save(\"PPO_quick\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9YONdho7NSx"
      },
      "source": [
        "Then, we load the model and see the performance of the state and action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UrET2aCty5ra",
        "outputId": "205044b7-a381-41c2-b808-05ba6b7e9b69"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = PPO(MlpPolicy, env, verbose=1)\n",
        "vec_env = model.get_env()\n",
        "model = PPO.load(\"PPO_quick\")\n",
        "obs = vec_env.reset()\n",
        "print(\"Initial observation\", obs)\n",
        "\n",
        "for i in range(24):\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = vec_env.step(action)\n",
        "plt.plot(np.array(env.statelist)[:,:-3])\n",
        "plt.title('Our Model Temperature')\n",
        "\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Celsius')\n",
        "plt.legend(['South','East','North','West','Core','Plenum','Outside'],loc='lower right')\n",
        "plt.show()\n",
        "plt.plot(np.sum(np.abs(np.array(env.actionlist)),1))\n",
        "plt.title('Our Model Power')\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('Watts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RnKqsZI_070X",
        "outputId": "a836de59-7af5-4769-ffe1-a02f8e001f9e"
      },
      "outputs": [],
      "source": [
        "plt.title('Quick PPO training')\n",
        "plt.plot(rewardlist)\n",
        "plt.xlabel('episode')\n",
        "plt.ylabel('reward')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNGLlh2C00Kg"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9GvZr6O-k2Gx",
        "lnOEOimqCOO1",
        "tjLijMJxCLCa",
        "wXQdt-0kCDG-"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
