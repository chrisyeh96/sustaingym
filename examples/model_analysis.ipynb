{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CallbackList, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "\n",
    "\n",
    "from sustaingym.envs import ElectricityMarketEnv\n",
    "from sustaingym.envs.battery.plot_utils import get_follow_offline_optimal, get_offline_optimal, setup_episode_plot, plot_episode, plot_model_training_reward_curves, plot_reward_distribution, plot_state_of_charge_and_prices, plot_reward_over_episode, run_model_for_evaluation\n",
    "from sustaingym.envs.battery.wrapped import DiscreteActions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_model_training_reward_curves(None, 'DQN_gamma9999', ['in_dist', 'out_dist'])\n",
    "\n",
    "# plt.savefig('examples/logs_PPO/ppo_reward_curves.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_model_training_reward_curves(None, 'DQN_term100', ['in_dist', 'out_dist'])\n",
    "\n",
    "# plt.savefig('examples/logs_A2C/a2c_reward_curves.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_2021 = ElectricityMarketEnv(month='2021-05', seed=215)\n",
    "\n",
    "\n",
    "ppo_2019 = PPO.load('examples/logs_PPO_2019/model_PPO_2019_5.zip')\n",
    "ppo_2021 = PPO.load('examples/logs_PPO_2021/model_PPO_2021_5.zip')\n",
    "dqn_2019 = DQN.load('examples/discrete_model_DQN_gamma9999_2019_5.zip')\n",
    "dqn_2021 = DQN.load('examples/discrete_logs_DQN_2021_5/model_DQN_2021_5.zip')\n",
    "\n",
    "ax = plot_reward_distribution(None, env_2021, [ppo_2021, ppo_2019, dqn_2021, dqn_2019],\n",
    "    ['ppo in dist', 'ppo out dist', 'dqn in dist', 'dqn out dist'], '2021')\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.savefig('algo_comp_2021.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_2019 = ElectricityMarketEnv(month='2019-05', seed=195)\n",
    "\n",
    "dqn = DQN.load('examples/discrete_model_DQN_2019_5.zip')\n",
    "\n",
    "results = run_model_for_evaluation(dqn, 1, DiscreteActions(env_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_2021 = ElectricityMarketEnv(month='2021-05', seed=215)\n",
    "\n",
    "# ppo = PPO.load('examples/model_PPO_2019_5.zip')\n",
    "# dqn = A2C.load('examples/discrete_model_DQN_2019_5.zip')\n",
    "\n",
    "# ax = plot_reward_distribution(None, env_2021, [ppo, dqn],\n",
    "#     ['ppo out dist', 'dqn out dist'], 10, '2021')\n",
    "\n",
    "# plt.savefig('algo_comp_2021.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gym\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "df_load = pd.read_csv('sustaingym/data/demand_data/CAISO-demand-2019-05.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "env = ElectricityMarketEnv(month='2019-05', seed=195)\n",
    "discrete_env = DiscreteActions(env)\n",
    "\n",
    "a2c = A2C.load('examples/discrete_model_A2C_2019_5.zip')\n",
    "\n",
    "ax, ax2 = plot_state_of_charge_and_prices(None, df_load, a2c, 'a2c in-dist', discrete_env)\n",
    "\n",
    "plt.savefig('prices_and_soc_over_episode.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ElectricityMarketEnv(month='2019-05', seed=195)\n",
    "env = DiscreteActions(env)\n",
    "ppo = PPO.load('examples/discrete_model_PPO_2019_5.zip')\n",
    "\n",
    "ax, ax2 = plot_reward_over_episode(None, ppo, env)\n",
    "\n",
    "plt.savefig('reward_over_epsiode.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ElectricityMarketEnv(month='2019-05', seed=195)\n",
    "\n",
    "# run offline optimal\n",
    "env.reset(seed=0)\n",
    "results = get_offline_optimal(seeds=[0], env=env)\n",
    "dispatch = results['dispatch']\n",
    "offline_data = {\n",
    "    'rewards': results['rewards'][0],\n",
    "    'prices': results['prices'][0],\n",
    "    'model_name': 'offline',\n",
    "    'energy_level': results['energy'][0]\n",
    "}\n",
    "\n",
    "# run follow optimal deterministic model\n",
    "env.reset(seed=0)\n",
    "follow_rewards, follow_energy, follow_prices = get_follow_offline_optimal(seeds=[0],\n",
    "                                                env=env, optimal_dispatches=dispatch, optimal_eng_lvl=results['energy'])\n",
    "follow_offline_data = {\n",
    "    'rewards': follow_rewards[0],\n",
    "    'prices': follow_prices[0],\n",
    "    'model_name': 'follow offline',\n",
    "    'energy_level': follow_energy[0]\n",
    "}\n",
    "\n",
    "# run PPO model\n",
    "env.reset(seed=0)\n",
    "ppo = PPO.load('examples/logs_PPO_2019/model_PPO_2019_5.zip')\n",
    "ppo_results = run_model_for_evaluation(ppo, 1, env, False)\n",
    "\n",
    "ppo_data = {\n",
    "    'rewards': ppo_results['rewards'][0],\n",
    "    'prices': ppo_results['prices'][0],\n",
    "    'model_name': 'ppo',\n",
    "    'energy_level': ppo_results['energies'][0],\n",
    "    'bids': ppo_results['actions'][0]\n",
    "}\n",
    "\n",
    "# run DQN model\n",
    "env.reset(seed=0)\n",
    "dqn = DQN.load('examples/discrete_model_DQN_gamma9999_2019_5.zip')\n",
    "dqn_results = run_model_for_evaluation(dqn, 1, env, True)\n",
    "\n",
    "dqn_data = {\n",
    "    'rewards': dqn_results['rewards'][0],\n",
    "    'prices': dqn_results['prices'][0],\n",
    "    'model_name': 'ppo',\n",
    "    'energy_level': dqn_results['energies'][0]\n",
    "}\n",
    "\n",
    "fig, axs, times = setup_episode_plot(env, '2019-05', include_bids=True)\n",
    "plot_episode(axs, times, **offline_data)\n",
    "plot_episode(axs, times, **follow_offline_data)\n",
    "plot_episode(axs, times, **ppo_data)\n",
    "plot_episode(axs, times, **dqn_data)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "\n",
    "plt.savefig('epsiode_plot.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9d7c3d8fd37e32a1feb97f344657397dd3fd2fa4ae2646ff5507371330127ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
