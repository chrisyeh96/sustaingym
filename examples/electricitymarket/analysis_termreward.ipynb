{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import stable_baselines3 as sb3\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sustaingym.envs import ElectricityMarketEnv\n",
    "from sustaingym.envs.battery.plot_utils import *\n",
    "from sustaingym.envs.battery.wrapped import DiscreteActions\n",
    "from sustaingym.evaluate.run_electricitymarket import *\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ElectricityMarketEnv(month='2021-05', seed=215, use_intermediate_rewards=False)\n",
    "discrete_env = DiscreteActions(env)\n",
    "reset_seed = 15\n",
    "seeds = np.arange(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run offline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = run_offline_optimal(seeds, env)\n",
    "save_results(opt_results, seeds=seeds, path='examples/termreward/offline_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = np.load('examples/termreward/offline_results.npz')\n",
    "follow_results = run_follow_offline_optimal(\n",
    "    seeds, env,\n",
    "    opt_dispatches=opt_results['dispatch'],\n",
    "    opt_energies=opt_results['energy'])\n",
    "save_results(follow_results, seeds=seeds, path='examples/termreward/follow_offline_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_random(seeds, env, discrete=False)\n",
    "save_results(results, seeds=seeds, path='examples/termreward/random_results.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_random(seeds, discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path='examples/termreward/random_discrete_results.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -a -m PPO -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -a -m PPO -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -a -m PPO -l 3e-05 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.003\n",
    "%run examples/train -y 2021 -a -m PPO -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -a -m PPO -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -a -m PPO -l 3e-05 -o examples/termreward\n",
    "\n",
    "\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m PPO -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m PPO -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with discrete actions, saved actions, and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m PPO -l 3e-05 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, and learning rate of 0.003\n",
    "%run examples/train -y 2021 -d -a -m PPO -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -d -a -m PPO -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with discrete actions, saved actions, and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -d -a -m PPO -l 3e-05 -o examples/termreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAC Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.003\n",
    "%run examples/train -y 2019 -v 2021 -a -m SAC -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.0003\n",
    "%run examples/train -y 2019 -v 2021 -a -m SAC -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 3e-05\n",
    "%run examples/train -y 2019 -v 2021 -a -m SAC -l 3e-05 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.003\n",
    "%run examples/train -y 2021 -a -m SAC -l 0.003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.0003\n",
    "%run examples/train -y 2021 -a -m SAC -l 0.0003 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 3e-05\n",
    "%run examples/train -y 2021 -a -m SAC -l 3e-05 -o examples/termreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Models\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.001\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m DQN -l 0.001 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 0.0001\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m DQN -l 0.0001 -o examples/termreward\n",
    "\n",
    "# Trained on year 2019 data (evaluating on year 2021 data during training phase) with saved actions and learning rate of 1e-05\n",
    "%run examples/train -y 2019 -v 2021 -d -a -m DQN -l 1e-05 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.001\n",
    "%run examples/train -y 2021 -d -a -m DQN -l 0.001 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 0.0001\n",
    "%run examples/train -y 2021 -d -a -m DQN -l 0.0001 -o examples/termreward\n",
    "\n",
    "# Trained on year 2021 data with saved actions and learning rate of 1e-5\n",
    "%run examples/train -y 2021 -d -a -m DQN -l 1e-05 -o examples/termreward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO 2019 model\n",
    "for model_name in ['PPO_2019_g0.9999_lr0.003', 'PPO_2019_g0.9999_lr0.0003', 'PPO_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO 2021 model\n",
    "for model_name in ['PPO_2021_g0.9999_lr0.003', 'PPO_2021_g0.9999_lr0.0003', 'PPO_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO discrete 2019 model\n",
    "for model_name in ['PPO_discrete_2019_g0.9999_lr0.003', 'PPO_discrete_2019_g0.9999_lr0.0003', 'PPO_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best PPO discrete 2021 model\n",
    "for model_name in ['PPO_discrete_2021_g0.9999_lr0.003', 'PPO_discrete_2021_g0.9999_lr0.0003', 'PPO_discrete_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best SAC 2019 model\n",
    "for model_name in ['SAC_2019_g0.9999_lr0.003', 'SAC_2019_g0.9999_lr0.0003', 'SAC_2019_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best SAC 2021 model\n",
    "for model_name in ['SAC_2021_g0.9999_lr0.003', 'SAC_2021_g0.9999_lr0.0003', 'SAC_2021_g0.9999_lr3e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best DQN 2019 model\n",
    "for model_name in ['DQN_discrete_2019_g0.9999_lr0.001', 'DQN_discrete_2019_g0.9999_lr0.0001', 'DQN_discrete_2019_g0.9999_lr1e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2019/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best DQN 2021 model\n",
    "for model_name in ['DQN_discrete_2021_g0.9999_lr0.001', 'DQN_discrete_2021_g0.9999_lr0.0001', 'DQN_discrete_2021_g0.9999_lr1e-05']:\n",
    "    evals_path = f'examples/termreward/{model_name}/eval2021/evaluations.npz'\n",
    "    npz = np.load(evals_path)\n",
    "    print(npz['results'].mean(axis=1).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2019_model_dir = 'examples/termreward/PPO_2019_g0.9999_lr0.003'\n",
    "ppo2021_model_dir = 'examples/termreward/PPO_2021_g0.9999_lr0.003'\n",
    "ppodiscrete2019_model_dir = 'examples/termreward/PPO_discrete_2019_g0.9999_lr0.003'\n",
    "ppodiscrete2021_model_dir = 'examples/termreward/PPO_discrete_2021_g0.9999_lr3e-05'\n",
    "sac2019_model_dir = 'examples/termreward/SAC_2019_g0.9999_lr0.0003/'\n",
    "sac2021_model_dir = 'examples/termreward/SAC_2021_g0.9999_lr3e-05/'\n",
    "dqn2019_model_dir = 'examples/termreward/DQN_discrete_2019_g0.9999_lr0.001/'\n",
    "dqn2021_model_dir = 'examples/termreward/DQN_discrete_2021_g0.9999_lr0.001/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2019 = sb3.PPO.load(os.path.join(ppo2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(ppo2019, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppo2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo2021 = sb3.PPO.load(os.path.join(ppo2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(ppo2021, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppo2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppodiscrete2019 = sb3.PPO.load(os.path.join(ppodiscrete2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(ppodiscrete2019, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppodiscrete2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppodiscrete2021 = sb3.PPO.load(os.path.join(ppodiscrete2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(ppodiscrete2021, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(ppodiscrete2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac2019 = sb3.SAC.load(os.path.join(sac2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(sac2019, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(sac2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sac2021 = sb3.SAC.load(os.path.join(sac2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(sac2021, seeds=seeds, env=env, discrete=False)\n",
    "save_results(results, seeds=seeds, path=os.path.join(sac2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn2019 = sb3.DQN.load(os.path.join(dqn2019_model_dir, 'eval2019/best_model.zip'))\n",
    "results = run_model(dqn2019, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(dqn2019_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn2021 = sb3.DQN.load(os.path.join(dqn2021_model_dir, 'eval2021/best_model.zip'))\n",
    "results = run_model(dqn2021, seeds=seeds, env=discrete_env, discrete=True)\n",
    "save_results(results, seeds=seeds, path=os.path.join(dqn2021_model_dir, 'eval2021/results.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paths = {\n",
    "    'oracle': 'examples/termreward/offline_results.npz',\n",
    "    'follow oracle': 'examples/termreward/follow_offline_results.npz',\n",
    "    'rand': 'examples/termreward/random_results.npz',\n",
    "    'rand discrete': 'examples/termreward/random_discrete_results.npz',\n",
    "\n",
    "    'PPO (2019)': os.path.join(ppo2019_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO (2021)': os.path.join(ppo2021_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO discrete (2019)': os.path.join(ppodiscrete2019_model_dir, 'eval2021/results.npz'),\n",
    "    'PPO discrete (2021)': os.path.join(ppodiscrete2021_model_dir, 'eval2021/results.npz'),\n",
    "    'SAC (2019)': os.path.join(sac2019_model_dir, 'eval2021/results.npz'),\n",
    "    'SAC (2021)': os.path.join(sac2021_model_dir, 'eval2021/results.npz'),\n",
    "    'DQN (2019)': os.path.join(dqn2019_model_dir, 'eval2021/results.npz'),\n",
    "    'DQN (2021)': os.path.join(dqn2021_model_dir, 'eval2021/results.npz')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {label: np.load(path) for label, path in results_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_returns(results, ylim=(-16000, 3000))\n",
    "fig.savefig('plots/em_returns_termreward.png', dpi=300, pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "ep_data = {}\n",
    "for label, d in results.items():\n",
    "    data = {k: d[k][seed] for k in ['rewards', 'prices', 'energy']}\n",
    "    data['model_name'] = label\n",
    "    if 'SAC (2021)' in label:\n",
    "        data['bids'] = d['actions'][seed]\n",
    "    if label == 'oracle':\n",
    "        data['rewards'] = np.zeros_like(data['rewards'])\n",
    "        data['rewards'][-1] = np.sum(d['rewards'][seed])\n",
    "    ep_data[label] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset(seed)\n",
    "fig, axs, times = setup_episode_plot(env, '2021-05', include_returns=True, include_bids=True)\n",
    "for label in ['oracle', 'follow oracle', 'rand', 'rand discrete', 'SAC (2021)', 'DQN (2021)', 'PPO discrete (2021)']:\n",
    "    plot_episode(axs, times, **ep_data[label])\n",
    "\n",
    "for plot in ['prices', 'energy', 'rewards', 'bids']:\n",
    "    axs[plot].legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('plots/em_episode_termreward.png', dpi=300, pad_inches=0, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sustaingym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c910351b0c3a4aade2cf03b555240fe9951314ae7b50b4f56bc279231ceafe8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
